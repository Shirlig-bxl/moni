#!/usr/bin/env python3
"""
æžé™GPUè´Ÿè½½è„šæœ¬ - ä¸“é—¨è§£å†³GPUåˆ©ç”¨çŽ‡0%é—®é¢˜
ä½¿ç”¨æœ€ç®€å•ä½†æœ€æœ‰æ•ˆçš„æ–¹æ³•è®©GPUåˆ©ç”¨çŽ‡è¾¾åˆ°90%+
"""

import torch
import torch.nn as nn
import torch.optim as optim
import time
from datetime import datetime

def log_with_timestamp(message):
    """å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] {message}")

def create_extreme_gpu_load():
    """åˆ›å»ºæžé™GPUè´Ÿè½½"""
    log_with_timestamp("ðŸ”¥ å¼€å§‹æžé™GPUè´Ÿè½½æµ‹è¯•")
    
    if not torch.cuda.is_available():
        log_with_timestamp("ERROR: CUDAä¸å¯ç”¨")
        return
    
    device = torch.device('cuda')
    log_with_timestamp(f"GPU: {torch.cuda.get_device_name(0)}")
    
    # èŽ·å–GPUå†…å­˜ä¿¡æ¯
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    log_with_timestamp(f"GPUæ€»å†…å­˜: {total_memory:.1f}GB")
    
    try:
        # æ–¹æ³•1: å¤§çŸ©é˜µè¿žç»­è®¡ç®—
        log_with_timestamp("ðŸš€ æ–¹æ³•1: å¤§çŸ©é˜µè¿žç»­è®¡ç®—")
        
        # æ ¹æ®GPUå†…å­˜åŠ¨æ€è°ƒæ•´çŸ©é˜µå¤§å°
        if total_memory >= 15:  # 15GB+
            matrix_size = 8192
            batch_count = 20
        elif total_memory >= 8:   # 8-15GB
            matrix_size = 6144
            batch_count = 15
        else:  # <8GB
            matrix_size = 4096
            batch_count = 10
        
        log_with_timestamp(f"çŸ©é˜µå¤§å°: {matrix_size}x{matrix_size}")
        
        for i in range(batch_count):
            # åˆ›å»ºå¤§çŸ©é˜µ
            a = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)
            b = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)
            
            # è¿žç»­çŸ©é˜µè¿ç®—
            for j in range(10):
                c = torch.matmul(a, b)
                a = torch.matmul(c, b.T)
                b = torch.matmul(a.T, c)
            
            gpu_memory = torch.cuda.memory_allocated() / 1024**2
            log_with_timestamp(f"  æ‰¹æ¬¡ {i+1}/{batch_count}, GPUå†…å­˜: {gpu_memory:.0f}MB")
            
            # çŸ­æš‚å»¶è¿Ÿè®©ç›‘æŽ§æ•èŽ·
            time.sleep(0.5)
        
        # æ–¹æ³•2: å¤šä¸ªå¤§æ¨¡åž‹åŒæ—¶è®­ç»ƒ
        log_with_timestamp("ðŸš€ æ–¹æ³•2: å¤šæ¨¡åž‹å¹¶è¡Œè®­ç»ƒ")
        
        # åˆ›å»ºå¤šä¸ªå¤§åž‹ç¥žç»ç½‘ç»œ
        models = []
        optimizers = []
        
        for i in range(3):  # 3ä¸ªå¹¶è¡Œæ¨¡åž‹
            model = nn.Sequential(
                nn.Linear(4096, 2048),
                nn.ReLU(),
                nn.Linear(2048, 2048),
                nn.ReLU(),
                nn.Linear(2048, 2048),
                nn.ReLU(),
                nn.Linear(2048, 1024),
                nn.ReLU(),
                nn.Linear(1024, 512),
                nn.ReLU(),
                nn.Linear(512, 10)
            ).to(device)
            
            optimizer = optim.Adam(model.parameters(), lr=0.001)
            models.append(model)
            optimizers.append(optimizer)
        
        criterion = nn.CrossEntropyLoss()
        
        # å¤§æ‰¹æ¬¡è®­ç»ƒ
        batch_size = 512
        
        for epoch in range(10):
            log_with_timestamp(f"å¤šæ¨¡åž‹è®­ç»ƒ Epoch {epoch+1}/10")
            
            for batch_idx in range(100):
                # ä¸ºæ¯ä¸ªæ¨¡åž‹åˆ›å»ºæ•°æ®å¹¶è®­ç»ƒ
                for model_idx, (model, optimizer) in enumerate(zip(models, optimizers)):
                    # åˆ›å»ºéšæœºæ•°æ®
                    inputs = torch.randn(batch_size, 4096, device=device)
                    targets = torch.randint(0, 10, (batch_size,), device=device)
                    
                    # å‰å‘ä¼ æ’­
                    outputs = model(inputs)
                    loss = criterion(outputs, targets)
                    
                    # åå‘ä¼ æ’­
                    optimizer.zero_grad()
                    loss.backward()
                    optimizer.step()
                
                # é¢å¤–çš„GPUå¯†é›†è®¡ç®—
                for k in range(5):
                    extra1 = torch.matmul(
                        torch.randn(batch_size, 1024, device=device),
                        torch.randn(1024, 2048, device=device)
                    )
                    extra2 = torch.conv2d(
                        torch.randn(batch_size, 64, 128, 128, device=device),
                        torch.randn(128, 64, 3, 3, device=device),
                        padding=1
                    )
                
                if batch_idx % 10 == 0:
                    gpu_memory = torch.cuda.memory_allocated() / 1024**2
                    log_with_timestamp(f"  Batch {batch_idx+1}/100, GPU: {gpu_memory:.0f}MB")
        
        # æ–¹æ³•3: è¿žç»­å·ç§¯æ“ä½œ
        log_with_timestamp("ðŸš€ æ–¹æ³•3: è¿žç»­å·ç§¯æ“ä½œ")
        
        # åˆ›å»ºå¤§åž‹å·ç§¯ç½‘ç»œ
        conv_model = nn.Sequential(
            nn.Conv2d(3, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 128, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 512, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(512, 1024, 3, padding=1),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(1024, 1000)
        ).to(device)
        
        conv_optimizer = optim.SGD(conv_model.parameters(), lr=0.01, momentum=0.9)
        
        # å¤§å›¾åƒæ‰¹æ¬¡
        img_batch_size = 64
        
        for i in range(200):
            # åˆ›å»ºå¤§å›¾åƒæ•°æ®
            images = torch.randn(img_batch_size, 3, 512, 512, device=device)  # å¤§å›¾åƒ
            targets = torch.randint(0, 1000, (img_batch_size,), device=device)
            
            # å‰å‘ä¼ æ’­
            outputs = conv_model(images)
            loss = criterion(outputs, targets)
            
            # åå‘ä¼ æ’­
            conv_optimizer.zero_grad()
            loss.backward()
            conv_optimizer.step()
            
            if i % 20 == 0:
                gpu_memory = torch.cuda.memory_allocated() / 1024**2
                log_with_timestamp(f"  å·ç§¯æ‰¹æ¬¡ {i+1}/200, GPU: {gpu_memory:.0f}MB")
        
        log_with_timestamp("ðŸŽ‰ æžé™GPUè´Ÿè½½æµ‹è¯•å®Œæˆ")
        
    except RuntimeError as e:
        if "out of memory" in str(e):
            log_with_timestamp("ðŸŽ¯ æˆåŠŸï¼GPUå†…å­˜å·²æ»¡ï¼Œè¯´æ˜ŽGPUè¢«å……åˆ†åˆ©ç”¨")
            log_with_timestamp("ðŸ’¡ è¿™æ˜¯é¢„æœŸçš„ç»“æžœï¼Œè¡¨æ˜ŽGPUè´Ÿè½½è¾¾åˆ°æžé™")
        else:
            log_with_timestamp(f"é”™è¯¯: {e}")
    
    finally:
        # æ¸…ç†GPUå†…å­˜
        torch.cuda.empty_cache()
        
        # æœ€ç»ˆçŠ¶æ€
        gpu_memory = torch.cuda.memory_allocated() / 1024**2
        log_with_timestamp(f"æœ€ç»ˆGPUå†…å­˜ä½¿ç”¨: {gpu_memory:.0f}MB")

def continuous_gpu_stress():
    """æŒç»­GPUåŽ‹åŠ›æµ‹è¯• - ä¿æŒé«˜åˆ©ç”¨çŽ‡"""
    log_with_timestamp("ðŸ”¥ å¼€å§‹æŒç»­GPUåŽ‹åŠ›æµ‹è¯•")
    
    if not torch.cuda.is_available():
        return
    
    device = torch.device('cuda')
    
    # åˆ›å»ºæŒç»­çš„GPUè´Ÿè½½
    matrices = []
    
    try:
        # åˆ†é…å¤§é‡GPUå†…å­˜
        for i in range(10):
            matrix = torch.randn(2048, 2048, device=device)
            matrices.append(matrix)
        
        log_with_timestamp("å¼€å§‹æŒç»­è®¡ç®—å¾ªçŽ¯...")
        
        # æŒç»­è®¡ç®—å¾ªçŽ¯
        for iteration in range(1000):
            # éšæœºé€‰æ‹©ä¸¤ä¸ªçŸ©é˜µè¿›è¡Œè¿ç®—
            idx1 = iteration % len(matrices)
            idx2 = (iteration + 1) % len(matrices)
            
            # æ‰§è¡Œè®¡ç®—å¯†é›†çš„æ“ä½œ
            result = torch.matmul(matrices[idx1], matrices[idx2])
            matrices[idx1] = torch.matmul(result, matrices[idx2].T)
            
            # é¢å¤–çš„è®¡ç®—
            extra = torch.sum(matrices[idx1] * matrices[idx2])
            
            if iteration % 50 == 0:
                gpu_memory = torch.cuda.memory_allocated() / 1024**2
                log_with_timestamp(f"  æŒç»­è®¡ç®— {iteration+1}/1000, GPU: {gpu_memory:.0f}MB")
                time.sleep(0.1)  # è®©ç›‘æŽ§æœ‰æ—¶é—´æ•èŽ·
    
    except Exception as e:
        log_with_timestamp(f"æŒç»­åŽ‹åŠ›æµ‹è¯•é”™è¯¯: {e}")
    
    finally:
        # æ¸…ç†
        matrices.clear()
        torch.cuda.empty_cache()

def main():
    """ä¸»å‡½æ•°"""
    log_with_timestamp("ðŸš€ æžé™GPUè´Ÿè½½è„šæœ¬å¯åŠ¨")
    log_with_timestamp("ç›®æ ‡: è®©GPUåˆ©ç”¨çŽ‡è¾¾åˆ°80%+")
    
    # è¿è¡Œæžé™GPUè´Ÿè½½
    create_extreme_gpu_load()
    
    # è¿è¡ŒæŒç»­åŽ‹åŠ›æµ‹è¯•
    continuous_gpu_stress()
    
    log_with_timestamp("âœ… æ‰€æœ‰GPUè´Ÿè½½æµ‹è¯•å®Œæˆ")
    log_with_timestamp("ðŸ’¡ çŽ°åœ¨æ£€æŸ¥GPUç›‘æŽ§ï¼Œåº”è¯¥çœ‹åˆ°æ˜¾è‘—çš„åˆ©ç”¨çŽ‡æå‡")

if __name__ == "__main__":
    main()