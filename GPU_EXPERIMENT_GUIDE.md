# GPUç¯å¢ƒå®Œæ•´å®éªŒæŒ‡å—

## ğŸ¯ æ–¹æ¡ˆé€‰æ‹©å»ºè®®

### ğŸ’° æˆæœ¬æ•ˆç›Šåˆ†æ

| æ–¹æ¡ˆ | æˆæœ¬ | æ—¶é—´é™åˆ¶ | GPUæ€§èƒ½ | æ¨èæŒ‡æ•° |
|------|------|----------|---------|----------|
| **Google Colab** | å…è´¹ | 12å°æ—¶/æ¬¡ | Tesla T4 | â­â­â­â­â­ |
| **Kaggle Notebooks** | å…è´¹ | 30å°æ—¶/å‘¨ | Tesla P100 | â­â­â­â­â­ |
| **é˜¿é‡Œäº‘ECS GPU** | Â¥2-3/å°æ—¶ | æ— é™åˆ¶ | Tesla T4 | â­â­â­â­ |
| **è…¾è®¯äº‘GPU** | Â¥8-12/å°æ—¶ | æ— é™åˆ¶ | Tesla V100 | â­â­â­ |

## ğŸ†“ æ–¹æ¡ˆä¸€ï¼šGoogle Colabï¼ˆæ¨èæ–°æ‰‹ï¼‰

### æ­¥éª¤1ï¼šå‡†å¤‡Colabç¯å¢ƒ
```python
# åœ¨Colabæ–°å»ºç¬”è®°æœ¬ï¼Œè¿è¡Œä»¥ä¸‹ä»£ç 

# 1. æ£€æŸ¥GPU
!nvidia-smi

# 2. å…‹éš†é¡¹ç›®
!git clone https://github.com/your-username/moni.git
%cd moni

# 3. å®‰è£…ä¾èµ–
!pip install -r requirements.txt

# 4. éªŒè¯ç¯å¢ƒ
import torch
print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
print(f"GPUåç§°: {torch.cuda.get_device_name(0)}")
```

### æ­¥éª¤2ï¼šè¿è¡Œå®Œæ•´å®éªŒ
```python
# è¿è¡Œå®Œæ•´çš„æ•…éšœæ³¨å…¥å®éªŒ
!python3 experiments/orchestrator.py

# æˆ–è€…åˆ†æ­¥è¿è¡Œ
!python3 experiments/baseline_run.py
!python3 experiments/fault_experiments.py --fault_type nan_loss
!python3 experiments/fault_experiments.py --fault_type oom
```

### æ­¥éª¤3ï¼šä¸‹è½½ç»“æœ
```python
# æ‰“åŒ…å®éªŒç»“æœ
!tar -czf experiment_results.tar.gz monitoring_data/ fault_experiments/ tse_matrix/ experiment_reports/

# ä¸‹è½½åˆ°æœ¬åœ°
from google.colab import files
files.download('experiment_results.tar.gz')
```

## ğŸ’° æ–¹æ¡ˆäºŒï¼šé˜¿é‡Œäº‘ECS GPUå®ä¾‹

### æ­¥éª¤1ï¼šåˆ›å»ºGPUå®ä¾‹

1. **ç™»å½•é˜¿é‡Œäº‘æ§åˆ¶å°**
   - è¿›å…¥ECSæ§åˆ¶å°
   - é€‰æ‹©"åˆ›å»ºå®ä¾‹"

2. **é€‰æ‹©GPUå®ä¾‹è§„æ ¼**
   ```
   æ¨èé…ç½®ï¼š
   - å®ä¾‹è§„æ ¼ï¼šecs.gn6i-c4g1.xlarge
   - GPUï¼šNVIDIA Tesla T4 (16GB)
   - CPUï¼š4æ ¸
   - å†…å­˜ï¼š15GB
   - ç³»ç»Ÿç›˜ï¼š40GB SSD
   - æ“ä½œç³»ç»Ÿï¼šUbuntu 20.04
   ```

3. **é…ç½®ç½‘ç»œå’Œå®‰å…¨ç»„**
   - å¼€æ”¾SSHç«¯å£(22)
   - å¼€æ”¾Jupyterç«¯å£(8888)ï¼ˆå¯é€‰ï¼‰

### æ­¥éª¤2ï¼šè¿æ¥å¹¶éƒ¨ç½²

```bash
# SSHè¿æ¥åˆ°å®ä¾‹
ssh root@your-instance-ip

# ä¸Šä¼ éƒ¨ç½²è„šæœ¬
scp deploy_aliyun_gpu.sh root@your-instance-ip:~/

# è¿è¡Œéƒ¨ç½²è„šæœ¬
chmod +x deploy_aliyun_gpu.sh
./deploy_aliyun_gpu.sh
```

### æ­¥éª¤3ï¼šä¸Šä¼ é¡¹ç›®ä»£ç 

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨scpä¸Šä¼ 
scp -r /Users/bytedance/Downloads/trae_projects/moni root@your-instance-ip:~/

# æ–¹æ³•2ï¼šä½¿ç”¨Gitï¼ˆæ¨èï¼‰
git clone https://github.com/your-username/moni.git
```

### æ­¥éª¤4ï¼šè¿è¡Œå®éªŒ

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source moni_env/bin/activate
cd moni

# è¿è¡Œå®Œæ•´å®éªŒ
python3 experiments/orchestrator.py

# ç›‘æ§GPUä½¿ç”¨æƒ…å†µ
watch -n 1 nvidia-smi
```

## ğŸš€ å½“å‰CPUç¯å¢ƒæµ‹è¯•

åœ¨ç­‰å¾…GPUèµ„æºçš„åŒæ—¶ï¼Œæ‚¨å¯ä»¥å…ˆè¿è¡Œæˆ‘ä¸ºæ‚¨å‡†å¤‡çš„CPUå®Œæ•´å®éªŒï¼š

<function_calls>
<invoke name="RunCommand">
<parameter name="command">python3 run_cpu_experiment.py