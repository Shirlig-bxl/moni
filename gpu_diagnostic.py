#!/usr/bin/env python3
"""
GPUè¯Šæ–­è„šæœ¬ - æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
ä¸“é—¨è¯Šæ–­ä¸ºä»€ä¹ˆGPUåˆ©ç”¨ç‡ä¸º0%
"""

import torch
import time
import psutil
from datetime import datetime

def check_gpu_basic():
    """åŸºç¡€GPUæ£€æŸ¥"""
    print("=" * 60)
    print("ğŸ” åŸºç¡€GPUç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            props = torch.cuda.get_device_properties(i)
            print(f"  - æ€»å†…å­˜: {props.total_memory / 1024**3:.1f} GB")
            print(f"  - è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")
        
        print(f"å½“å‰GPUè®¾å¤‡: {torch.cuda.current_device()}")
        return True
    else:
        print("âŒ CUDAä¸å¯ç”¨ï¼")
        print("ğŸ’¡ è¯·æ£€æŸ¥:")
        print("   1. Colabè¿è¡Œæ—¶æ˜¯å¦è®¾ç½®ä¸ºGPU")
        print("   2. è¿è¡Œæ—¶ â†’ æ›´æ”¹è¿è¡Œæ—¶ç±»å‹ â†’ ç¡¬ä»¶åŠ é€Ÿå™¨ â†’ GPU")
        return False

def test_gpu_computation():
    """æµ‹è¯•GPUè®¡ç®—èƒ½åŠ›"""
    print("\n" + "=" * 60)
    print("ğŸ§ª GPUè®¡ç®—èƒ½åŠ›æµ‹è¯•")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("âŒ è·³è¿‡GPUæµ‹è¯• - CUDAä¸å¯ç”¨")
        return False
    
    device = torch.device('cuda')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æµ‹è¯•1: ç®€å•çŸ©é˜µè¿ç®—
    print("\nğŸ“Š æµ‹è¯•1: çŸ©é˜µè¿ç®—")
    try:
        # åˆ›å»ºå¤§çŸ©é˜µè¿›è¡Œè®¡ç®—
        size = 2000
        print(f"åˆ›å»º {size}x{size} çŸ©é˜µ...")
        
        a = torch.randn(size, size, device=device)
        b = torch.randn(size, size, device=device)
        
        print("å¼€å§‹çŸ©é˜µä¹˜æ³•...")
        start_time = time.time()
        
        # æ‰§è¡Œå¤šæ¬¡è®¡ç®—ä»¥äº§ç”ŸGPUè´Ÿè½½
        for i in range(10):
            c = torch.matmul(a, b)
            if i % 2 == 0:
                print(f"  è®¡ç®—è½®æ¬¡ {i+1}/10...")
            time.sleep(0.5)  # ç»™ç›‘æ§æ—¶é—´è§‚å¯Ÿ
        
        end_time = time.time()
        print(f"âœ… çŸ©é˜µè¿ç®—å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        print(f"ç»“æœçŸ©é˜µå½¢çŠ¶: {c.shape}")
        print(f"GPUå†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
        
        return True
        
    except Exception as e:
        print(f"âŒ GPUè®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_gpu_usage():
    """æµ‹è¯•æ¨¡å‹GPUä½¿ç”¨"""
    print("\n" + "=" * 60)
    print("ğŸ¤– æ¨¡å‹GPUä½¿ç”¨æµ‹è¯•")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("âŒ è·³è¿‡æ¨¡å‹æµ‹è¯• - CUDAä¸å¯ç”¨")
        return False
    
    try:
        device = torch.device('cuda')
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ
        print("åˆ›å»ºç¥ç»ç½‘ç»œ...")
        model = torch.nn.Sequential(
            torch.nn.Linear(1000, 512),
            torch.nn.ReLU(),
            torch.nn.Linear(512, 256),
            torch.nn.ReLU(),
            torch.nn.Linear(256, 2)
        ).to(device)
        
        print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
        print(f"æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = torch.nn.CrossEntropyLoss()
        
        print("\nå¼€å§‹è®­ç»ƒå¾ªç¯...")
        batch_size = 64
        
        for epoch in range(5):
            print(f"Epoch {epoch+1}/5")
            
            for step in range(20):  # 20ä¸ªæ­¥éª¤
                # åˆ›å»ºéšæœºæ•°æ®
                inputs = torch.randn(batch_size, 1000, device=device)
                targets = torch.randint(0, 2, (batch_size,), device=device)
                
                # å‰å‘ä¼ æ’­
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                
                # åå‘ä¼ æ’­
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                
                if step % 5 == 0:
                    print(f"  Step {step+1}/20, Loss: {loss.item():.4f}")
                    print(f"  GPUå†…å­˜: {torch.cuda.memory_allocated() / 1024**2:.1f} MB")
                
                time.sleep(0.2)  # ç»™ç›‘æ§æ—¶é—´è§‚å¯Ÿ
        
        print("âœ… æ¨¡å‹è®­ç»ƒæµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹GPUæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def monitor_gpu_during_test():
    """åœ¨æµ‹è¯•æœŸé—´ç›‘æ§GPU"""
    print("\n" + "=" * 60)
    print("ğŸ“Š GPUç›‘æ§æµ‹è¯•")
    print("=" * 60)
    
    try:
        import pynvml
        pynvml.nvmlInit()
        handle = pynvml.nvmlDeviceGetHandleByIndex(0)
        
        print("å¼€å§‹GPUç›‘æ§ï¼ˆ10ç§’ï¼‰...")
        
        for i in range(10):
            # è·å–GPUåˆ©ç”¨ç‡
            util = pynvml.nvmlDeviceGetUtilizationRates(handle)
            
            # è·å–GPUå†…å­˜
            mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            
            # è·å–GPUæ¸©åº¦
            temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
            
            print(f"[{i+1:2d}/10] GPUåˆ©ç”¨ç‡: {util.gpu:3d}%, "
                  f"å†…å­˜: {mem_info.used//1024//1024:4d}/{mem_info.total//1024//1024:4d}MB "
                  f"({mem_info.used/mem_info.total*100:5.1f}%), "
                  f"æ¸©åº¦: {temp:2d}Â°C")
            
            time.sleep(1)
        
        return True
        
    except ImportError:
        print("âŒ pynvmlæœªå®‰è£…ï¼Œæ— æ³•ç›‘æ§GPU")
        print("ğŸ’¡ å®‰è£…å‘½ä»¤: pip install nvidia-ml-py3")
        return False
    except Exception as e:
        print(f"âŒ GPUç›‘æ§å¤±è´¥: {e}")
        return False

def comprehensive_gpu_test():
    """ç»¼åˆGPUæµ‹è¯•"""
    print("ğŸ§ª GPUè¯Šæ–­ - ç»¼åˆæµ‹è¯•")
    print("è¿™ä¸ªæµ‹è¯•å°†å¸®åŠ©è¯Šæ–­ä¸ºä»€ä¹ˆGPUåˆ©ç”¨ç‡ä¸º0%")
    print("=" * 60)
    
    # 1. åŸºç¡€æ£€æŸ¥
    gpu_available = check_gpu_basic()
    
    if not gpu_available:
        print("\nâŒ GPUä¸å¯ç”¨ï¼Œè¯·å…ˆè§£å†³GPUç¯å¢ƒé—®é¢˜")
        return
    
    # 2. å¯åŠ¨GPUç›‘æ§ï¼ˆåå°ï¼‰
    import threading
    
    def background_monitor():
        time.sleep(2)  # ç­‰å¾…æµ‹è¯•å¼€å§‹
        monitor_gpu_during_test()
    
    monitor_thread = threading.Thread(target=background_monitor)
    monitor_thread.daemon = True
    monitor_thread.start()
    
    # 3. GPUè®¡ç®—æµ‹è¯•
    print("\nğŸš€ å¼€å§‹GPUè´Ÿè½½æµ‹è¯•...")
    time.sleep(1)
    
    compute_success = test_gpu_computation()
    
    # 4. æ¨¡å‹æµ‹è¯•
    model_success = test_model_gpu_usage()
    
    # ç­‰å¾…ç›‘æ§å®Œæˆ
    monitor_thread.join(timeout=15)
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“‹ è¯Šæ–­æ€»ç»“")
    print("=" * 60)
    
    print(f"âœ… GPUç¯å¢ƒ: {'æ­£å¸¸' if gpu_available else 'å¼‚å¸¸'}")
    print(f"âœ… GPUè®¡ç®—: {'æ­£å¸¸' if compute_success else 'å¼‚å¸¸'}")
    print(f"âœ… æ¨¡å‹è®­ç»ƒ: {'æ­£å¸¸' if model_success else 'å¼‚å¸¸'}")
    
    if gpu_available and compute_success and model_success:
        print("\nğŸ‰ GPUåŠŸèƒ½æ­£å¸¸ï¼")
        print("ğŸ’¡ å¦‚æœæ‚¨çš„è®­ç»ƒä»ç„¶GPUåˆ©ç”¨ç‡ä¸º0%ï¼Œå¯èƒ½çš„åŸå› :")
        print("   1. è®­ç»ƒæ•°æ®å¤ªå°ï¼ŒGPUå¤„ç†å¤ªå¿«")
        print("   2. batch_sizeå¤ªå°ï¼Œæ— æ³•å……åˆ†åˆ©ç”¨GPU")
        print("   3. æ¨¡å‹æ²¡æœ‰æ­£ç¡®ç§»åŠ¨åˆ°GPU")
        print("   4. æ•°æ®æ²¡æœ‰ç§»åŠ¨åˆ°GPU")
    else:
        print("\nâš ï¸ å‘ç°GPUé—®é¢˜ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°å¤±è´¥çš„æµ‹è¯•é¡¹")

if __name__ == "__main__":
    comprehensive_gpu_test()