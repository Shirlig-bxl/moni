# 主动故障注入与多源异常数据收集系统实施方案

## 项目概述
构建一个完整的"观测器-执行器-注入器"系统，用于主动制造并捕获多源异常，生成带有精确 Ground Truth 标注的数据集，用于训练和验证 TSE-Matrix 和 MLH-AD 框架。

## 阶段一：环境与工具准备

### 1.1 项目结构搭建
```
moni/
├── src/
│   ├── executor/           # 执行器模块
│   │   ├── train.py       # 主训练脚本
│   │   └── config.py      # 训练配置
│   ├── observer/          # 观测器模块
│   │   ├── gpu_monitor.py # GPU指标监控
│   │   ├── system_monitor.py # 系统指标监控
│   │   └── log_parser.py  # 日志解析器
│   ├── injector/          # 注入器模块
│   │   ├── fault_injector.py # 故障注入控制器
│   │   ├── io_stress.py   # I/O压力测试
│   │   └── resource_competitor.py # 资源争用模拟
│   └── aggregator/        # 数据聚合模块
│       ├── data_aggregator.py # 数据聚合器
│       └── tse_matrix_builder.py # TSE矩阵构建器
├── experiments/           # 实验脚本
│   ├── baseline_run.py    # 基线运行脚本
│   ├── fault_experiments.py # 故障注入实验
│   └── orchestrator.py    # 实验编排器
├── data/                  # 数据目录
│   ├── raw/              # 原始监控数据
│   ├── processed/        # 处理后数据
│   └── datasets/         # 最终数据集
├── configs/              # 配置文件
│   ├── training_configs/ # 训练配置
│   └── fault_configs/    # 故障配置
└── requirements.txt      # 依赖包
```

### 1.2 核心依赖安装
- PyTorch + Transformers (Hugging Face)
- nvidia-ml-py3 (GPU监控)
- psutil (系统监控)
- pandas, numpy (数据处理)
- datasets (IMDB数据集)

## 阶段二：核心组件实现

### 2.1 执行器 (Executor) 实现
- **train.py**: 基于 Hugging Face Trainer API 的 BERT-IMDB 微调脚本
- **config.py**: 可配置的训练参数（支持故障注入参数）
- 支持多种故障模式：NaN Loss、OOM、收敛失败

### 2.2 观测器 (Observer) 实现
- **gpu_monitor.py**: 
  - 使用 nvidia-smi 每秒采集 GPU 利用率、显存使用
  - 输出格式化的 CSV 文件
- **system_monitor.py**:
  - 使用 psutil 采集 CPU、内存、磁盘 I/O
  - 与 GPU 监控时间戳对齐
- **log_parser.py**:
  - 实时解析训练日志
  - 提取 Loss、Accuracy、Throughput 等指标
  - 识别异常事件 (OOM, NaN, WARNING)

### 2.3 注入器 (Injector) 实现
- **fault_injector.py**: 故障注入控制器
- **io_stress.py**: I/O 瓶颈模拟脚本
- **resource_competitor.py**: 资源争用模拟（启动竞争进程）

## 阶段三：实验设计与执行

### 3.1 基线实验
- 健康训练配置的完整运行
- 生成正常模式的多源数据
- 用于 L3 AutoEncoder 训练和 L0 阶段识别验证

### 3.2 故障注入实验矩阵
| 故障类型 | 注入方式 | 预期异常 | Ground Truth 标注 |
|---------|---------|---------|------------------|
| NaN Loss | learning_rate=10.0 | Loss瞬时异常 | Loss变NaN时间戳 |
| OOM | batch_size=1024 | 显存溢出+崩溃 | OOM事件时间戳 |
| 不收敛 | learning_rate=1e-9 | Loss/Acc长程异常 | 整个训练周期 |
| I/O瓶颈 | 磁盘压力测试 | GPU利用率周期性下降 | 压力测试时间窗口 |
| 资源争用 | 启动竞争进程 | 多指标稀疏异常 | 竞争进程运行窗口 |
| 进程终止 | kill -9 | 心跳停止异常 | kill命令时间戳 |

### 3.3 实验编排
- **orchestrator.py**: 自动化实验执行
- 支持批量运行多种故障场景
- 自动启动/停止监控进程
- 实验结果自动归档

## 阶段四：数据聚合与TSE-Matrix构建

### 4.1 时间戳对齐
- 统一1秒时间粒度
- 多源数据时间戳同步
- 处理数据缺失和延迟

### 4.2 特征工程
- GPU指标: utilization, memory_used, memory_total
- 系统指标: cpu_percent, memory_percent, disk_io_read, disk_io_write
- 训练指标: loss, accuracy, learning_rate, throughput
- 事件指标: event_oom, event_nan, event_warning (二值化)

### 4.3 Ground Truth标注
- 基于故障注入时间窗口的精确标注
- 支持点异常、区间异常、全局异常标注
- 生成符合 TSE-Matrix 格式的最终数据集

## 阶段五：验证与优化

### 5.1 数据质量验证
- 检查时间戳对齐准确性
- 验证异常标注的正确性
- 统计各类异常的分布情况

### 5.2 框架集成测试
- L0 阶段识别模块测试
- L2 Isolation Forest 异常检测测试
- L3 AutoEncoder 正常模式学习测试

## 预期产出
1. **多源对齐数据集**: 包含6种典型异常的时序数据
2. **精确Ground Truth**: 基于真实故障注入的准确标注
3. **可复现实验**: 完整的实验脚本和配置
4. **验证报告**: 各层检测算法的性能验证结果

## 技术亮点
- **真实性**: 基于实际ML训练任务的真实异常
- **多样性**: 覆盖模型、数据、资源、系统多个层面
- **精确性**: 毫秒级时间戳对齐和精确异常标注
- **可扩展性**: 模块化设计，易于添加新的故障类型